{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3823d72-e2d1-44c8-836c-f1f3e181553c",
   "metadata": {},
   "source": [
    "# Introduction to JACC.jl\n",
    "<img src=\"../images/JACC-logo.png\" alt=\"JACC logo\" style=\"width:15%;height:auto;\">\n",
    "\n",
    "## Motivation\n",
    "Different HPC systems have different hardware and thus different vendor-provided APIs.\n",
    "\n",
    "We want performance portability and programming productivity. That is:\n",
    "\n",
    "**_Program once; deploy everywhere!_**\n",
    "\n",
    "<img src=\"../images/HPC-systems-vendors.png\" alt=\"HPC Systems and Vendors\" style=\"width:75%;height:auto;\">\n",
    "\n",
    "### Options for (data) parallelism in Julia\n",
    "CPU multi-threading\n",
    "- Threads (built-in)\n",
    "- Polyester\n",
    "- OhMyThreads\n",
    "\n",
    "GPU kernel model (fine-granularity):\n",
    "- Vendor-specific packages:\n",
    "  - CUDA, AMDGPU, oneAPI, Metal\n",
    "- KernelAbstractions\n",
    "  - Portable interface implemented by each vendor package\n",
    "\n",
    "The aim of JACC is to provide a familiar interface and smart defaults, bringing good performance closer to domain scientists who may not be experts in computer science.\n",
    "- high-level unified Julia front-end on top of multiple backends (Threads, CUDA, AMDGPU, oneAPI)\n",
    "- Hide low-level and device-specific implementation\n",
    "- Improve programming productivity for science and HPC\n",
    "- A growing community\n",
    "  - LBNL/NERSC, LANL, Argonne, MIT, ETHZ, BSC, Cerfacs, FI/CCQ, â€¦\n",
    "  - You are welcome to join (JACC community meetings once a month)\n",
    "  - Reach out on [github](https://github.com/JuliaORNL/JACC.jl/discussions)\n",
    "<img src=\"../images/JACC-stack.png\" alt=\"JACC stack\" style=\"width:25%;height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28012c00-99bd-47dd-bd62-6735ea0c2e47",
   "metadata": {},
   "source": [
    "## Simple Exercises\n",
    "1. Allocate an array and use a parallel_for to initialize the elements (e.g., using the index values)\n",
    "2. Allocate an array of ones and find the sum of the elements using parallel_reduce.\n",
    "3. Try #2 using a parallel_for with @atomic\n",
    "\n",
    "(Bonus) Create a struct holding an array and use it in a kernel. (This is not a challenge for CPU-only code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5609336-4dd7-4fc2-a762-4929dca86389",
   "metadata": {},
   "source": [
    "## Getting started with JACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514ec9c-7687-454e-8a15-4e01d6024e5b",
   "metadata": {},
   "source": [
    "##### 1. Add JACC as a dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c537790-43cb-459b-aa83-87b318325e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"JACC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa692897-b710-4e5c-be5f-fdc9f0e94eea",
   "metadata": {},
   "source": [
    "##### 2. Set backend\n",
    "This will install the appropriate backend package as a dependency for the current project (don't commit this!).\n",
    "\n",
    "NOTE: in some cases you may need to configure the backend package before proceeding to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71010202-27a0-4d8f-804c-7b0c4d89558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import JACC\n",
    "JACC.set_backend(\"oneapi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d306bb-1ee2-4861-a1d7-a7eefae58c1b",
   "metadata": {},
   "source": [
    "##### 3. Restart Julia\n",
    "For this notebook, use the menu: \"Kernel\" > \"Restart Kernel...\" (With the REPL in a terminal you would simply quit and restart `julia`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1a1ad-62f2-45b1-9c0d-101156d17f88",
   "metadata": {},
   "source": [
    "##### 4. Load extension before use\n",
    "Equivalent to\n",
    "```julia\n",
    "import <backend-package>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6114ed-3757-49e4-87fa-cac2e9eda110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import JACC\n",
    "JACC.@init_backend\n",
    "\n",
    "# Show current backend\n",
    "JACC.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea286e-0b9e-4657-8d44-ba8eb77f4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "JACC.supported_backends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af2ec1-5086-4896-87df-dd481a8ca886",
   "metadata": {},
   "source": [
    "## JACC paradigm basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc4bd1-2262-49c8-8155-cf8de1d08519",
   "metadata": {},
   "source": [
    "##### `JACC.array`\n",
    "Constructs a backend-managed array (copying to device if necessary). There is no separate array type in JACC.\n",
    "\n",
    "##### `JACC.ones`, `JACC.zeros`, `JACC.fill`\n",
    "Create initialized arrays (same as `Base` API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f60011-dcc2-4c09-8358-3a818b4acbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ones(3,2)\n",
    "@show a, typeof(a)\n",
    "\n",
    "ad1 = JACC.array(a)\n",
    "@show ad1, typeof(ad1)\n",
    "\n",
    "ad2 = JACC.ones(2, 2)\n",
    "@show ad2, typeof(ad2)\n",
    "\n",
    "ad3 = JACC.fill(2.5, 5)\n",
    "@show ad3, typeof(ad3)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93b367-41c6-4ae1-bd14-6099839ac96b",
   "metadata": {},
   "source": [
    "- `JACC.parallel_for` and `JACC.parallel_reduce`\n",
    "  - Kernel function passed as an argument\n",
    "  - Unidimensional and multidimensional APIs\n",
    "\n",
    "Example: define `axpy` and `dot` as kernel functions for 1D and 2D arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0da3ae-29aa-4435-aec2-6226638483ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unidimensional arrays\n",
    "function axpy(i, alpha, x, y)\n",
    "    x[i] += alpha * y[i]\n",
    "end\n",
    "function dot(i, x, y)\n",
    "    return x[i] * y[i]\n",
    "end\n",
    "SIZE = 1_000_000\n",
    "x = round.(rand(Float64, SIZE) * 100)\n",
    "y = round.(rand(Float64, SIZE) * 100)\n",
    "alpha = 2.5\n",
    "dx = JACC.array(x)\n",
    "dy = JACC.array(y)\n",
    "JACC.parallel_for(SIZE, axpy, alpha, dx, dy)\n",
    "res = JACC.parallel_reduce(SIZE, dot, dx, dy)\n",
    "\n",
    "# Multidimensional arrays\n",
    "function axpy(i, j, alpha, x, y)\n",
    "    x[i, j] += alpha * y[i, j]\n",
    "end\n",
    "function dot(i, j, x, y)\n",
    "    return x[i, j] * y[i, j]\n",
    "end\n",
    "SIZE = 1_000\n",
    "x = round.(rand(Float64, SIZE, SIZE) * 100)\n",
    "y = round.(rand(Float64, SIZE, SIZE) * 100)\n",
    "alpha = 2.5\n",
    "dx = JACC.array(x)\n",
    "dy = JACC.array(y)\n",
    "JACC.parallel_for((SIZE, SIZE), axpy, alpha, dx, dy)\n",
    "res = JACC.parallel_reduce((SIZE, SIZE), dot, dx, dy)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d99b6a-4326-4686-9084-0c7213da91f7",
   "metadata": {},
   "source": [
    "#### Performance results for simple kernels\n",
    "<img src=\"../images/JACC-perfresults-01.png\" alt=\"Performance Results\" style=\"width:90%;height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd6688-2840-4617-8e0c-d7c6bc54bfde",
   "metadata": {},
   "source": [
    "## JACC paradigm basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ee8b8-9b80-460d-8f27-62c059e67243",
   "metadata": {},
   "source": [
    "From a serial loop to a `JACC.parallel_for` (multiple options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c4185-b22c-4b4b-8b4e-be7f941da644",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "alpha = 2.5\n",
    "x = ones(N)\n",
    "y = ones(N)\n",
    "x_d = JACC.ones(N)\n",
    "y_d = JACC.ones(N)\n",
    "\n",
    "### Serial loop\n",
    "for i = 1:N\n",
    "    @inbounds x[i] += alpha * y[i]\n",
    "end\n",
    "###\n",
    "\n",
    "### JACC do-style\n",
    "JACC.parallel_for(N, alpha, x_d, y_d) do i, a, x, y\n",
    "    @inbounds x[i] += a * y[i]\n",
    "end\n",
    "###\n",
    "\n",
    "### JACC with pre-defined function\n",
    "JACC.parallel_for(N, axpy, alpha, x_d, y_d)\n",
    "###\n",
    "\n",
    "### JACC with anonymous function\n",
    "JACC.parallel_for(N,\n",
    "    (i, a, x, y) -> begin           #\n",
    "        @inbounds x[i] += a * y[i]  # anonymous function\n",
    "    end,                            #\n",
    "    alpha, x_d, y_d)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cf0bf-216b-49b1-b9f0-3f91c18ce1a5",
   "metadata": {},
   "source": [
    "_**NOTE**_: Items must be passed explicitly. If you implicitly reference names from the parent surrounding scope, you will be attempting to access host memory from the device (unless you're using the \"threads\" backend)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cffa70-fe54-4745-811e-1abe82b8dca6",
   "metadata": {},
   "source": [
    "Let's see a slightly more involved example and use a named tuple for arguments.\n",
    "\n",
    "```julia\n",
    "### Serial loop\n",
    "for i = 1:length(events)\n",
    "    @inbounds begin\n",
    "        event = events[i, 6:8]\n",
    "        weight = events[i, 1]\n",
    "        for op in transforms\n",
    "            v = op * event\n",
    "            atomic_push!(hist, v, weight)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "### JACC do-style\n",
    "JACC.parallel_for(   # named tuple\n",
    "    length(events), (h = hist, events, transforms)) do i, t\n",
    "    @inbounds begin\n",
    "        event = t.events[i, 6:8]\n",
    "        weight = t.events[i, 1]\n",
    "        for op in t.transforms\n",
    "            v = op * event\n",
    "            atomic_push!(t.h, v, weight)\n",
    "        end\n",
    "    end\t\t\n",
    "end\n",
    "###\n",
    "\n",
    "### JACC with anonymous function\n",
    "JACC.parallel_for(length(events),\n",
    "    (i, t) -> begin\n",
    "        @inbounds begin\n",
    "            event = t.events[i, 6:8]\n",
    "            weight = t.events[i, 1]\n",
    "            for op in t.transforms\n",
    "                v = op * event\n",
    "                atomic_push!(t.h, v, weight)\n",
    "            end\n",
    "        end\t\t\n",
    "    end,\n",
    "    (h = hist, events, transforms), # named tuple\n",
    ")\n",
    "###\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47861995-0d9e-4966-8555-4c22b67dd3b5",
   "metadata": {},
   "source": [
    "The basic `JACC.parallel_reduce` API:\n",
    "\n",
    "```julia\n",
    "parallel_reduce(N, op, f, xâ€¦; init) -> typeof(init)\n",
    "parallel_reduce(N, f, xâ€¦) = parallel_reduce(N, +, f, xâ€¦; init = 0.0)\n",
    "parallel_reduce([op = +,] a::AbstractArray; init = default_init(eltype(a), op)) -> typeof(init)\n",
    "# op âˆŠ {+, *, min, max, <user-defined>}\n",
    "```\n",
    "\n",
    "Here are a few simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f752b-d55a-45a5-99cd-13fcdbb8be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = JACC.array([i for i in 1:10])\n",
    "@show JACC.parallel_reduce(a)\n",
    "@show JACC.parallel_reduce(min, a)\n",
    "\n",
    "b = JACC.fill(2, 10)\n",
    "b_min = JACC.parallel_reduce(10, min, (i, b) -> b[i] + i, b; init = Inf)\n",
    "@show b_min\n",
    "\n",
    "dp = JACC.parallel_reduce(10, a, b) do i, a, b\n",
    "    a[i] * b[i]\n",
    "end\n",
    "@show dp\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3346673-4c85-4475-8059-f5d1dac2ee4d",
   "metadata": {},
   "source": [
    "## Notes for GPU programming\n",
    "- Any function can be used in a kernel (without special annotation) as long as it doesn't allocate\n",
    "- JACC imports the `@atomic` macro from [Atomix.jl](https://github.com/JuliaConcurrent/Atomix.jl)\n",
    "- Use [StaticArrays.jl](https://github.com/JuliaArrays/StaticArrays.jl) for small fixed-size arrays\n",
    "- Use [Adapt.jl](https://github.com/JuliaGPU/Adapt.jl) if you need to put GPU arrays in a struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d84439-98d0-478d-aacd-cdd6a14d5198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
