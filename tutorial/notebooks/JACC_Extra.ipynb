{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92254bbb-1a94-40a2-a0a5-42323289daf3",
   "metadata": {},
   "source": [
    "# Some special features of JACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e830b4-7ec0-4a72-be9b-03c8bb94e4c9",
   "metadata": {},
   "source": [
    "## Finer granularity\n",
    "\n",
    "Defaults for `JACC.parallel_for`:\n",
    "- Synchronize\n",
    "- Use default stream\n",
    "- Compute threads, blocks, and shmem_size\n",
    "\n",
    "```julia\n",
    "@kwdef mutable struct LaunchSpec{Backend}\n",
    "    stream = default_stream(Backend)\n",
    "    threads = 0\n",
    "    blocks = 0\n",
    "    shmem_size::Int = 0\n",
    "    sync::Bool = false\n",
    "end\n",
    "\n",
    "launch_spec(; kw...) = LaunchSpec{typeof(default_backend())}(; kw...)\n",
    "\n",
    "```\n",
    "\n",
    "You can change these defaults using `JACC.launch_spec`.\n",
    "\n",
    "Specify one or more of the keywords and call `JACC.parallel_for(spec, N, f, x…)`.\n",
    "\n",
    "```julia\n",
    "JACC.parallel_for(JACC.launch_spec(; threads = 1000), N,\n",
    "    (i, a) -> begin\n",
    "        @inbounds a[i] += 5.0\n",
    "    end, a_device)\n",
    "JACC.synchronize() # non-synchronized by default\n",
    "\n",
    "```\n",
    "\n",
    "There are more details about this and `parallel_reduce` but we'll skip those here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4e753-b1ed-4e44-aa2e-01bc9b68309f",
   "metadata": {},
   "source": [
    "## Shared Memory\n",
    "\n",
    "See the [paper](https://ieeexplore.ieee.org/document/10938453).\n",
    "\n",
    "The `JACC.shared` gives easy access to on-chip GPU shared memory. If you access an array many times per thread, you may get significant speedup by adding just one line.\n",
    "\n",
    "<img src=\"../images/GPU-shared-memory.png\" alt=\"GPU shared memory\" style=\"width:45%;height:auto;\">\n",
    "\n",
    "```julia\n",
    "function spectral(i, j, image, filter, num_bands)\n",
    "    for b in 1:num_bands\n",
    "        @inbounds image[b, i, j] *= filter[j]\n",
    "    end\n",
    "end\n",
    "\n",
    "function spectral_shared(i, j, image, filter, num_bands)\n",
    "    filter_shared = JACC.shared(filter) # init shared memory\n",
    "    for b in 1:num_bands\n",
    "        @inbounds image[b, i, j] *= filter_shared[j]\n",
    "    end\n",
    "end\n",
    "\n",
    "num_bands = 60\n",
    "num_voxel = 10_240\n",
    "size_voxel = 64*64\n",
    "image = init_image(Float32, num_bands, num_voxel, size_voxel)\n",
    "filter = init_filter(Float32, size_voxel)\n",
    "jimage = JACC.array(image)\n",
    "jfilter = JACC.array(filter)\n",
    "\n",
    "JACC.parallel_for((num_voxel,size_voxel), spectral[_shared], jimage, jfilter, num_bands)\n",
    "\n",
    "```\n",
    "\n",
    "Things to keep in mind about `JACC.shared`:\n",
    "- X is a JACC.array and Y is a copy of X stored in on-chip shared memory\n",
    "- X can be any dimension\n",
    "- Y must be a unidimensional array (currently)\n",
    "- To be used inside functions\n",
    "- The array passed as argument must fit the capacity of the shared memory\n",
    "\n",
    "<img src=\"../images/JACC-perfresults-shared.png\" alt=\"JACC.shared Performance Results\" style=\"width:90%;height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779080a-9875-4f00-9404-58233789ef79",
   "metadata": {},
   "source": [
    "## Exploiting multi-GPU nodes\n",
    "\n",
    "Submodule `JACC.Multi`\n",
    "- Deploy JACC’s specification to multi-GPU\n",
    "- Same API (just add `Multi`)\n",
    "\n",
    "JACC.Multi.array: `JX = JACC.Multi.array(X)`\n",
    "- X is evenly distributed into the different GPUs\n",
    "- JX is an backend-specific structure for managing a set of sub-arrays\n",
    "\n",
    "JACC.Multi.parallel_for and JACC.Multi.parallel_reduce\n",
    "- Same API, but...\n",
    "- Launches portion of workload on all devices\n",
    "\n",
    "```julia\n",
    "# Unidimensional arrays\n",
    "function axpy(i, alpha, x, y)\n",
    "    x[i] += alpha * y[i]\n",
    "end\n",
    "function dot(i, x, y)\n",
    "    return x[i] * y[i]\n",
    "end\n",
    "SIZE = 1_000_000\n",
    "x = round.(rand(Float64, SIZE) * 100)\n",
    "y = round.(rand(Float64, SIZE) * 100)\n",
    "alpha = 2.5\n",
    "dx = JACC.Multi.array(x)\n",
    "dy = JACC.Multi.array(y)\n",
    "JACC.Multi.parallel_for(SIZE, axpy, alpha, dx, dy)\n",
    "res = JACC.Multi.parallel_reduce(SIZE, dot, dx, dy)\n",
    "\n",
    "# Multidimensional arrays\n",
    "function axpy_2d(i, j, alpha, x, y)\n",
    "    x[i, j] += alpha * y[i, j]\n",
    "end\n",
    "function dot_2d(i, j, x, y)\n",
    "    return x[i, j] * y[i, j]\n",
    "end\n",
    "SIZE = 1_000\n",
    "x = round.(rand(Float64, SIZE, SIZE) * 100)\n",
    "y = round.(rand(Float64, SIZE, SIZE) * 100)\n",
    "alpha = 2.5\n",
    "dx = JACC.Multi.array(x)\n",
    "dy = JACC.Multi.array(y)\n",
    "JACC.Multi.parallel_for((SIZE, SIZE), axpy_2d, alpha, dx, dy)\n",
    "res = JACC.Multi.parallel_reduce((SIZE, SIZE), dot_2d, dx, dy)\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"../images/JACC-perfresults-multi.png\" alt=\"JACC.Multi Performance Results\" style=\"width:90%;height:auto;\">\n",
    "\n",
    "- There are additional functions for managing ghost elements between devices.\n",
    "- _More thorough example in tests_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6630388-3bf9-4d5a-b4e4-e52011f6bad1",
   "metadata": {},
   "source": [
    "# Applications and Ongoing Efforts\n",
    "\n",
    "Examples and applications using JACC\n",
    "- https://github.com/tdehoff/JACC-7-point-stencil\n",
    "- https://github.com/JuliaORNL/JACC-applications\n",
    "- https://github.com/JuliaORNL/MiniVATES.jl\n",
    "- https://github.com/JuliaORNL/GrayScott.jl\n",
    "\n",
    "Ongoing Efforts\n",
    "- Performance benchmarking (closing gaps)\n",
    "- Expanded API (covering more use-cases)\n",
    "- More intuitive kernel launch\n",
    "- JACC.Async : Concurrency on multi-device nodes\n",
    "- JACC.Auto : Autotuning\n",
    "- Have ideas? Send us a message!\n",
    "\n",
    "Other HPC Julia tutorial resources\n",
    "- SC24 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a266e-5a92-47d3-8717-98d11b9e573f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
